#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/opencv.hpp>
#include <iostream>
#include <torch/script.h>
#include <dlfcn.h>
#include <typeinfo>
#include <string>
#include <cstring>
#include <vector>
#include <windows.h>
#include <time.h>
#include <tuple>
using namespace std;
using namespace cv;
void _nms(int* keep_out, int* num_out, const float* boxes_host, int boxes_num,
	int boxes_dim, float nms_overlap_thresh, int device_id);
//split string function
vector<string> split(string &str, char ch)
{
	vector<string> res;
	str += ch;
	int start = 0;
	int last = str.find(ch);
	while (last < str.size())
	{
		if (start != last)
			res.push_back(str.substr(start, last - start));
		start = last + 1;
		last = str.find(ch, start);
	}
	return res;
}

typedef struct Score
{
	int id;
	float score;
}Score;

bool sort_Score(Score sc1, Score sc2)
{
	return (sc1.score > sc2.score);

}
int main(){
	//const char* customOpsFolder = "D:\\data\\tanglin\\maskrcnn_c++\\dll\\custom_ops_no_opencv.cp36-win_amd64.dll";
	void* custom_op_lib = dlopen("custom_ops_no_opencv.cp36-win_amd64.dll", RTLD_NOW | RTLD_GLOBAL);//load custom ops

	if (custom_op_lib == NULL) {
		cerr << "could not open custom op library: " << dlerror() << endl;
	}

	cout << "load detection algorithm ...." << endl;


	/*load model*/
	std::shared_ptr<torch::jit::script::Module> module = torch::jit::load("D:\\data\\tanglin\\maskrcnn_c++\\model_pose_gpu.pt");
	//torch::jit::script::Module module = torch::jit::load("D:\\data\\tanglin\\maskrcnn_c++\\model_gpu.pt");
	assert(module != nullptr);

	//torch::Device device(torch::cuda::is_available() ? torch::kCUDA : torch::kCPU);
	torch::DeviceType device_type;
	//device_type = torch::kCPU;  
	device_type = torch::kCUDA;  //set cuda or cpu
	torch::Device device(device_type, 0);
	module->to(device);

	//cout << "finished load model" << endl;


	/*read images*/
	std::vector<cv::String> filenames;
	cv::String folder = "D:\\data\\tanglin\\maskrcnn_c++\\川大原图\\Picture2"; //images folder
	cv::String save_folder = "D:\\data\\tanglin\\maskrcnn_c++\\result\\川大\\"; //save folder
	cv::glob(folder, filenames);

	for (int i = 0; i<filenames.size(); ++i) {
		std::cout << filenames[i] << std::endl;
		string filename = filenames[i];;
		vector<string> filename_str = split(filename, '\\');
		cv::Mat img_ = cv::imread(filenames[i]);
		cv:Mat image_ori = img_;
		double height_ori = img_.cols;
		double width_ori = img_.rows;
		double hratio = 0.7;
		double wratio = 0.7;
		double ratio[2];
//-----------------------------------------
		int keep[100];
		int num_out = 0;
		float box_in[500][6]; // x1,y1,x2,y2,kind,score
		memset(keep, 0, sizeof(keep));
		memset(box_in, 0, sizeof(box_in));
// -----------------------------------------
		ratio[0] = (double)(height_ori*wratio) / double(1312);
		ratio[1] = (double)(width_ori*hratio) / double(960);
		cv::Mat img1 = img_(Range(0, (int)(wratio * width_ori)), Range(0, (int)(hratio * height_ori)));
		cv::Mat img2 = img_(Range(0, (int)(wratio * width_ori)), Range(height_ori - (int)(hratio* height_ori), height_ori));
		cv::Mat img3 = img_(Range(width_ori - (int)(wratio*width_ori), width_ori), Range(0, (int)(hratio * height_ori)));
		cv::Mat img4 = img_(Range(width_ori - (int)(wratio*width_ori), width_ori), Range(height_ori - (int)(hratio* height_ori), height_ori));
		std::tuple<cv::Mat, cv::Mat, cv::Mat, cv::Mat> img_4part(img1, img2, img3, img4);
		int standNum = 0, sitNum = 0, lieNum = 0;
		torch::Tensor box1, box2, box3, box4, kind1, kind2, kind3, kind4, score1, score2, score3, score4;
		torch::Tensor box;
		torch::Tensor score;
		torch::Tensor kind;
		int flag = 0;
		for (int p = 0;p < 4;p++)
		{
			cv::Mat img(960, 1312, CV_8UC3);
			if (p == 0)
			{
				cv::resize(img1, img, img.size(), 0, 0, cv::INTER_LINEAR);  // must be bilinear interpolation,it fits our works more
				auto input_ = torch::tensor(at::ArrayRef<uint8_t>(img.data, img.rows * img.cols * 3)).view({ img.rows, img.cols, 3 });
				/* data -> model */
				std::vector<torch::jit::IValue> inputs;
				inputs.push_back(input_);
				bool error_flag;  //runtime error flag
				try {
					auto result_tr = module->forward(inputs);
					error_flag = false;
				}
				catch (std::runtime_error) {
					error_flag = true;
				}
				std::vector<c10::IValue, std::allocator<c10::IValue>> res; //res must be this type
				auto result = module->forward(inputs);
				auto tuple = (result.toTuple())->elements();
				res = tuple;
				box1 = res[0].toTensor();
				for (int tt = 0;tt < box1.size(0);tt++)
				{
					box1[tt][1] = box1[tt][1] * ratio[1];
					box1[tt][3] = box1[tt][3] * ratio[1];
					box1[tt][0] = box1[tt][0] * ratio[0];
					box1[tt][2] = box1[tt][2] * ratio[0];
				}
				kind = res[1].toTensor();
				score = res[2].toTensor();
			}
			else if (p == 1)
			{
				cv::resize(img2, img, img.size(), 0, 0, cv::INTER_LINEAR);  // must be bilinear interpolation,it fits our works more
				auto input_ = torch::tensor(at::ArrayRef<uint8_t>(img.data, img.rows * img.cols * 3)).view({ img.rows, img.cols, 3 });
				/* data -> model */
				std::vector<torch::jit::IValue> inputs;
				inputs.push_back(input_);
				bool error_flag;  //runtime error flag
				try {
					auto result_tr = module->forward(inputs);
					error_flag = false;
				}
				catch (std::runtime_error) {
					error_flag = true;
				}
				std::vector<c10::IValue, std::allocator<c10::IValue>> res; //res must be this type
				auto result = module->forward(inputs);
				auto tuple = (result.toTuple())->elements();
				res = tuple;
				box2 = res[0].toTensor();
				for (int tt = 0;tt < box2.size(0);tt++)
				{
					box2[tt][0] = box2[tt][0] * ratio[0] + (int)((1 - hratio)*(height_ori));
					box2[tt][1] = box2[tt][1] * ratio[1];
					box2[tt][2] = box2[tt][2] * ratio[0] + (int)((1 - hratio)*(height_ori));
					box2[tt][3] = box2[tt][3] * ratio[1];
				}
				kind2 = res[1].toTensor();
				score2 = res[2].toTensor();
				
			}
			else if (p == 2)
			{
				cv::Mat img(960, 1312, CV_8UC3);
				cv::resize(img3, img, img.size(), 0, 0, cv::INTER_LINEAR);  // must be bilinear interpolation,it fits our works more
				auto input_ = torch::tensor(at::ArrayRef<uint8_t>(img.data, img.rows * img.cols * 3)).view({ img.rows, img.cols, 3 });
				/* data -> model */
				std::vector<torch::jit::IValue> inputs;
				inputs.push_back(input_);
				bool error_flag;  //runtime error flag
				try {
					auto result_tr = module->forward(inputs);
					error_flag = false;
				}
				catch (std::runtime_error) {
					error_flag = true;
				}
				std::vector<c10::IValue, std::allocator<c10::IValue>> res; //res must be this type
				auto result = module->forward(inputs);
				auto tuple = (result.toTuple())->elements();
				res = tuple;
				box3 = res[0].toTensor();
				for (int tt = 0;tt < box3.size(0);tt++)
				{
					box3[tt][0] = box3[tt][0] * ratio[0];
					box3[tt][1] = box3[tt][1] * ratio[1] + (int)((1 - wratio)*(width_ori));
					box3[tt][2] = box3[tt][2] * ratio[0];
					box3[tt][3] = box3[tt][3] * ratio[1] + (int)((1 - wratio)*(width_ori));
				}
				kind3 = res[1].toTensor();
				score3 = res[2].toTensor();
			}
			else if (p == 3)
			{
				cv::Mat img(960, 1312, CV_8UC3);
				cv::resize(img4, img, img.size(), 0, 0, cv::INTER_LINEAR);  // must be bilinear interpolation,it fits our works more
				auto input_ = torch::tensor(at::ArrayRef<uint8_t>(img.data, img.rows * img.cols * 3)).view({ img.rows, img.cols, 3 });
				/* data -> model */
				std::vector<torch::jit::IValue> inputs;
				inputs.push_back(input_);
				bool error_flag;  //runtime error flag
				try {
					auto result_tr = module->forward(inputs);
					error_flag = false;
				}
				catch (std::runtime_error) {
					error_flag = true;
				}
				std::vector<c10::IValue, std::allocator<c10::IValue>> res; //res must be this type
				auto result = module->forward(inputs);
				auto tuple = (result.toTuple())->elements();
				res = tuple;
				box4 = res[0].toTensor();
				for (int tt = 0;tt < box4.size(0);tt++)
				{
					box4[tt][0] = box4[tt][0] * ratio[0] + (int)((1 - hratio)*(height_ori));
					box4[tt][1] = box4[tt][1] * ratio[1] + (int)((1 - wratio)*(width_ori));
					box4[tt][2] = box4[tt][2] * ratio[0] + (int)((1 - hratio)*(height_ori));
					box4[tt][3] = box4[tt][3] * ratio[1] + (int)((1 - wratio)*(width_ori));
				}
				kind4 = res[1].toTensor();
				score4 = res[2].toTensor();
			}
		}



		cout << box.size(0) << endl;
		int number = box.size(0); //the people number for the image
		for (int j = 0; j<number; j++) {
			auto x1 = (box[j][0]).item().toFloat();
			auto y1 = (box[j][1]).item().toFloat();
			auto x2 = (box[j][2]).item().toFloat();
			auto y2 = (box[j][3]).item().toFloat();
			if (kind[j].item().toFloat() == 1)
			{
				rectangle(img_, cvPoint(x1, y1), cvPoint(x2, y2), CV_RGB(0, 255, 0), 2, 8, 0);
				standNum++;
			}
			else if (kind[j].item().toFloat() == 2)
			{
				rectangle(img_, cvPoint(x1, y1), cvPoint(x2, y2), CV_RGB(0, 0, 255), 2, 8, 0);
				sitNum++;
			}
			else if (kind[j].item().toFloat() == 3)
			{
				rectangle(img_, cvPoint(x1, y1), cvPoint(x2, y2), CV_RGB(255, 0, 0), 2, 8, 0);
				lieNum++;
			}
		}
		cout << "peopleCount = " << standNum + sitNum + lieNum << "\nstanding = " << standNum << "\nsitting = " << sitNum << "\nlying = " << lieNum << endl;
		cv::imwrite(save_folder + filename_str[filename_str.size() - 1], img_);
		//cout << "model can be caculate" << endl;

	}

 
	
	getchar();
 	return 0;
  
}
